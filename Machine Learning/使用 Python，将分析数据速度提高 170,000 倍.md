原文：[Analyzing Data 170,000x Faster with Python](https://sidsite.com/posts/python-corrset-optimization/)

---

# 使用 Python，将分析数据速度提高 170,000 倍
 

这篇 [使用 Rust，将分析数据速度提高 180,000 倍](https://willcrichton.net/notes/k-corrset/)首先介绍了一些未优化的 Python 代码，然后展示了用 Rust 重写和优化代码的过程，从而实现了 180,000 倍的加速。作者指出：


> 
> 有很多方法可以使 Python 代码更快，但本文的重点不是将高度优化的 Python 与高度优化的 Rust 进行比较。其重点是将“标准 Jupyter 笔记本”形式的 Python 与高度优化的 Rust 进行比较。
> 
> 

问题来了：如果我们坚持使用 Python，那么我们可以实现什么样的速度提升？

在这篇文章中，我们将在 Python 中经历一次分析和迭代加速代码的旅程。


#### 复制原始基准

这篇文章中的时间与原始文章中报告的时间相当。使用类似的计算机（M1 Macbook Pro），我测量得到：

* 原始未优化代码的平均迭代时间为 35 毫秒，经过 1,000 多次迭代测量。原始文章则为 36 毫秒。
* 对于完全优化的 Rust 代码，加速超过 180,081 倍，测量通过超过 5,000,000 次迭代完成。原始文章则为 182,450x。


### Python 基线

下面是基线的一个副本，它是未优化的 Python 代码，来自这篇[文章](https://willcrichton.net/notes/k-corrset/)。

```py
from itertools import combinations
import pandas as pd
from pandas import IndexSlice as islice

def k_corrset(data, K):
    all_qs = data.question.unique()
    q_to_score = data.set_index(['question', 'user'])
    all_grand_totals = data.groupby('user').score.sum().rename('grand_total')

    # Inner loop
    corrs = []
    for qs in combinations(all_qs, K):
        qs_data = q_to_score.loc[islice[qs,:],:].swaplevel()
        answered_all = qs_data.groupby(level=[0]).size() == K
        answered_all = answered_all[answered_all].index
        qs_totals = qs_data.loc[islice[answered_all,:]] \
            .groupby(level=[0]).sum().rename(columns={'score': 'qs'})
        r = qs_totals.join(all_grand_totals).corr().qs.grand_total
        corrs.append({'qs': qs, 'r': r})
    corrs = pd.DataFrame(corrs)

    return corrs.sort_values('r', ascending=False).iloc[0].qs

data = pd.read_json('scores.json')
print(k_corrset(data, K=5))
```

这是 dataframe `data` 的前两行。


| user | question | score |
| --- | --- | --- |
| e213cc2b-387e-4d7d-983c-8abc19a586b1 | d3bdb068-7245-4521-ae57-d0e9692cb627 | 1 |
| 951ffaee-6e17-4599-a8c0-9dfd00470cd9 | d3bdb068-7245-4521-ae57-d0e9692cb627 | 0 |


我们可以使用原始代码的输出来测试优化代码的正确性。

由于我们正在尝试优化内部循环，故而我们将内部循环放入其自己的函数中，以使用 [line_profiler](https://github.com/pyutils/line_profiler) 对其进行分析。


```sh
Avg time per iteration:  35 ms
Speedup over baseline:   1.0x

% Time  Line Contents
=====================
        def compute_corrs(
            qs_iter: Iterable, q_to_score: pd.DataFrame, grand_totals: pd.DataFrame
        ):
   0.0      result = []
   0.0      for qs in qs_iter:
  13.5          qs_data = q_to_score.loc[islice[qs, :], :].swaplevel()
  70.1          answered_all = qs_data.groupby(level=[0]).size() == K
   0.4          answered_all = answered_all[answered_all].index
   0.0          qs_total = (
   6.7              qs_data.loc[islice[answered_all, :]]
   1.1              .groupby(level=[0])
   0.6              .sum()
   0.3              .rename(columns={"score": "qs"})
                )
   7.4          r = qs_total.join(grand_totals).corr().qs.grand_total
   0.0          result.append({"qs": qs, "r": r})
   0.0      return result
```

我们可以看到我们试图优化的值（平均迭代时间/加速比），以及每行花费的时间比例。

以下是优化代码的工作流程：

* 运行分析器
* 识别最慢的代码行
* 试着让较慢的代码行快点
* 重复

如果只有几行代码占据了大部分时间，我们就知道具体要关注什么，从上面我们看到有一行特别慢的代码，它占据了大约 70% 的时间。


### 优化 1 - 包含回答问题的用户的集合字典，*users_who_answered_q*

基线执行各种繁重的 Pandas 操作，以找出哪些用户回答了当前的一组问题 `qs`。特别是，它检查数据帧的每一行以找出哪些用户回答了问题。对于第一个优化，我们可以使用集合字典，而不是使用完整的数据帧。这让我们可以快速查找哪些用户回答了 `qs` 中的每个问题，并使用 Python 的集合交集来找出哪些用户回答了所有问题。


```sh
Avg time per iteration:  10.0 ms
Speedup over baseline:   3.5x

% Time  Line Contents
=====================
        def compute_corrs(qs_iter, users_who_answered_q, q_to_score, grand_totals):
   0.0      result = []
   0.0      for qs in qs_iter:
   0.0          user_sets_for_qs = [users_who_answered_q[q] for q in qs]
   3.6          answered_all = set.intersection(*user_sets_for_qs)
  40.8          qs_data = q_to_score.loc[islice[qs, :], :].swaplevel()
   0.0          qs_total = (
  22.1              qs_data.loc[islice[list(answered_all), :]]
   3.7              .groupby(level=[0])
   1.9              .sum()
   1.1              .rename(columns={"score": "qs"})
                )
  26.8          r = qs_total.join(grand_totals).corr().qs.grand_total
   0.0          result.append({"qs": qs, "r": r})
   0.0      return result
```

这显着加快了计算行的速度 `answered_all`，从占用 70% 的时间降低到 4%，并且我们的速度已经比基线快了 3 倍以上。


### 优化 2 - *score_dict* 字典

如果我们将用于计算 `qs_total` 的每行代码（包括 `qs_data` 这一行）的时间相加，则约为 65%；所以接下来要优化哪一个就很清楚了。我们可以再次通过快速字典查找来切换对整个数据集的繁重操作（索引、分组等）。我们引入了`score_dict`，这是一个字典，可以让我们查找给定问题和用户对的分数。


```sh
Avg time per iteration:  690 μs
Speedup over baseline:   50.8x

% Time  Line Contents
=====================
        def compute_corrs(qs_iter, users_who_answered_q, score_dict, grand_totals):
   0.0      result = []
   0.0      for qs in qs_iter:
   0.1          user_sets_for_qs = [users_who_answered_q[q] for q in qs]
  35.9          answered_all = set.intersection(*user_sets_for_qs)
   3.4          qs_total = {u: sum(score_dict[q, u] for q in qs) for u in answered_all}
   8.6          qs_total = pd.DataFrame.from_dict(qs_total, orient="index", columns=["qs"])
   0.1          qs_total.index.name = "user"
  51.8          r = qs_total.join(grand_totals).corr().qs.grand_total
   0.0          result.append({"qs": qs, "r": r})
   0.0      return result
```

这使我们的速度提高了 50 倍。

### 优化 3 - *grand_totals* 字典和 np.corrcoef


上面最慢那一行做了几件事，它进行一个 Pandas join 操作，将 `grand_totals` 和 `qs_total` 组合在一起，然后计算其相关系数。同样，我们可以通过使用字典查找而不是 join 来提升速度，此外，由于我们不再使用 Pandas 对象，因此，我们使用 `np.corrcoef` 来代替 Pandas `corr`。


```sh
Avg time per iteration:  380 μs
Speedup over baseline:   91.6x

% Time  Line Contents
=====================
        def compute_corrs(qs_iter, users_who_answered_q, score_dict, grand_totals):
   0.0      result = []
   0.0      for qs in qs_iter:
   0.2          user_sets_for_qs = [users_who_answered_q[q] for q in qs]
  83.9          answered_all = set.intersection(*user_sets_for_qs)
   7.2          qs_total = [sum(score_dict[q, u] for q in qs) for u in answered_all]
   0.5          user_grand_total = [grand_totals[u] for u in answered_all]
   8.1          r = np.corrcoef(qs_total, user_grand_total)[0, 1]
   0.1          result.append({"qs": qs, "r": r})
   0.0      return result
```

这使我们的速度提高了约 90 倍。


### 优化 4 - 将 uuid 字符串转换成整数

下一个优化完全不会更改内循环中的代码。但它确实提高了某些操作的速度。我们用更短的整数来替换长的用户/问题 uuid（例如， `e213cc2b-387e-4d7d-983c-8abc19a586b1`）。完成方法是：


```py
data.user = data.user.map({u: i for i, u in enumerate(data.user.unique())})
data.question = data.question.map(
    {q: i for i, q in enumerate(data.question.unique())}
)
```

然后进行评估：

```sh
Avg time per iteration:  210 μs
Speedup over baseline:   168.5x

% Time  Line Contents
=====================
        def compute_corrs(qs_iter, users_who_answered_q, score_dict, grand_totals):
   0.0      result = []
   0.1      for qs in qs_iter:
   0.4          user_sets_for_qs = [users_who_answered_q[q] for q in qs]
  71.6          answered_all = set.intersection(*user_sets_for_qs)
  13.1          qs_total = [sum(score_dict[q, u] for q in qs) for u in answered_all]
   0.9          user_grand_total = [grand_totals[u] for u in answered_all]
  13.9          r = np.corrcoef(qs_total, user_grand_total)[0, 1]
   0.1          result.append({"qs": qs, "r": r})
   0.0      return result
```

### 优化 5 - np.bool_ 数组取代用户集

我们可以看到上面的 set 操作仍然是最慢的一行。我们可以转为使用一个类型为 `np.bool_` 的用户数组来取代整数集，然后使用 `np.logical_and.reduce` 来查找那些回答了 `qs` 中所有问题的用户。（注意，虽然 `np.bool_` 中的每个元素都是一个完整的字节，但是 `np.logical_and.reduce` 仍然很快。）这带来了显著的速度提升：


```sh
Benchmark #6: NumPy bool_ array to identify users who answered qs
Using 1000 iterations...

Avg time per iteration:  75 μs
Speedup over baseline:   466.7x

% Time  Line Contents
=====================
        def compute_corrs(qs_iter, users_who_answered_q, score_dict, grand_totals):
   0.0      result = []
   0.1      for qs in qs_iter:
  12.0          user_sets_for_qs = users_who_answered_q[qs, :]  # numpy indexing
   9.9          answered_all = np.logical_and.reduce(user_sets_for_qs)
  10.7          answered_all = np.where(answered_all)[0]
  33.7          qs_total = [sum(score_dict[q, u] for q in qs) for u in answered_all]
   2.6          user_grand_total = [grand_totals[u] for u in answered_all]
  30.6          r = np.corrcoef(qs_total, user_grand_total)[0, 1]
   0.2          result.append({"qs": qs, "r": r})
   0.0      return result
```

### 优化 6 - *score_matrix* 代替 dict

上面最慢的一行现在是计算 `qs_total` 了。按照原始文章中的例子，我们改用一个密集的 np.array 来查找分数，而不是使用字典，然后使用快速的 NumPy 索引来获取分数。

```sh
Avg time per iteration:  56 μs
Speedup over baseline:   623.7x

% Time  Line Contents
=====================
        def compute_corrs(qs_iter, users_who_answered_q, score_matrix, grand_totals):
   0.0      result = []
   0.2      for qs in qs_iter:
  16.6          user_sets_for_qs = users_who_answered_q[qs, :]
  14.0          answered_all = np.logical_and.reduce(user_sets_for_qs)
  14.6          answered_all = np.where(answered_all)[0]
   7.6          qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)
   3.9          user_grand_total = [grand_totals[u] for u in answered_all]
  42.7          r = np.corrcoef(qs_total, user_grand_total)[0, 1]
   0.4          result.append({"qs": qs, "r": r})
   0.0      return result
```

### 优化 7 - 自定义 *corrcoef*

上面最慢的一行是 `np.corrcoef`……我们将尽一切努力来优化我们的代码，所以这是我们自己实现的 corrcoef，对于这个用例来说，它带来了两杯的速度提升：

```py
def corrcoef(a: list[float], b: list[float]) -> float | None:
    """same as np.corrcoef(a, b)[0, 1]"""
    n = len(a)
    sum_a = sum(a)
    sum_b = sum(b)
    sum_ab = sum(a_i * b_i for a_i, b_i in zip(a, b))
    sum_a_sq = sum(a_i**2 for a_i in a)
    sum_b_sq = sum(b_i**2 for b_i in b)
    num = n * sum_ab - sum_a * sum_b
    den = sqrt(n * sum_a_sq - sum_a**2) * sqrt(n * sum_b_sq - sum_b**2)
    if den == 0:
        return None
    return num / den
```

我们得到了不错的速度提升：

```sh
Avg time per iteration:  43 μs
Speedup over baseline:   814.6x

% Time  Line Contents
=====================
        def compute_corrs(qs_iter, users_who_answered_q, score_matrix, grand_totals):
   0.0      result = []
   0.2      for qs in qs_iter:
  21.5          user_sets_for_qs = users_who_answered_q[qs, :]  # numpy indexing
  18.7          answered_all = np.logical_and.reduce(user_sets_for_qs)
  19.7          answered_all = np.where(answered_all)[0]
  10.0          qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)
   5.3          user_grand_total = [grand_totals[u] for u in answered_all]
  24.1          r = corrcoef(qs_total, user_grand_total)
   0.5          result.append({"qs": qs, "r": r})
   0.0      return result
```

### 优化 8 - 早期引入 Numba

在上面的代码中，我们尚未完成数据结构的优化，但让我们来看下，如果在这个阶段引入了 [Numba](https://numba.pydata.org/)，会发生什么呢。Numba 是 Python 生态中的一个库，它“将 Python 和 NumPy 代码的一个子集转换为快速的机器码”。

为了能够使用 Numba，我们做了两个改动：

改动 1：将 qs_combinations 作为 numpy 数组传递，而不是 `qs_iter`

Numba 不能很好地与 `itertools` 或者生成器配合使用，因此，我们提前将 `qs_iter` 转换为 NumPy 数组，然后才将它传给对应函数。此更改对运行时间的影响（添加 Numba 之前）如下所示。

```sh
Avg time per iteration:  42 μs
Speedup over baseline:   829.2x

```

改动 2：结果使用数组，而不是列表

我们初始化一个数组，然后将结果放入其中，而不是将结果附加到列表中。此更改对运行时间的影响（添加 Numba 之前）如下所示。


```sh
Avg time per iteration:  42 μs
Speedup over baseline:   833.8x

```

最终，代码看起来像是这样的：


```py
import numba

@numba.njit(parallel=False)
def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):
    result = np.empty(len(qs_combinations), dtype=np.float64)
    for i in numba.prange(len(qs_combinations)):
        qs = qs_combinations[i]
        user_sets_for_qs = users_who_answered_q[qs, :]
        # numba doesn't support np.logical_and.reduce
        answered_all = user_sets_for_qs[0]
        for j in range(1, len(user_sets_for_qs)):
            answered_all *= user_sets_for_qs[j]
        answered_all = np.where(answered_all)[0]
        qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)
        user_grand_total = grand_totals[answered_all]
        result[i] = corrcoef_numba(qs_total, user_grand_total)
    return result
```

（请注意，我们还用了 Numba 来装饰 `corrcoef`，因为 Numba 函数中的函数调用也需要经过编译。）

#### 使用 *parallel=False* 的结果


```sh
Avg time per iteration:  47 μs
Speedup over baseline:   742.2x

```

#### 使用 *parallel=True* 的结果



```sh
Avg time per iteration:  8.5 μs
Speedup over baseline:   4142.0x

```

我们看到，使用 `parallel=False` 的情况下， Numba 代码比之前的 Python 代码慢一点，但当我们使用了并行，从而开始使用所有的 CPU 核（运行基准测试的机器上有 10 个），这带来了很棒的速度倍增。

然而，我们失去了在 JIT 编译的代码上使用 [line_profiler](https://github.com/pyutils/line_profiler) 的能力（我们可能想开始查看生成的 LLVM IR/汇编）。


### 优化 9 - Bitset，不使用 Numba

我们暂时把 Numba 放在一边。原始文章使用 bitset 来快速计算回答了当前 `qs` 中问题的用户，所以，看看这是否适合我们。我们可以使用 `np.int64` 类型的 NumPy 数组以及  `np.bitwise_and.reduce` 来实现 bitset。这与我们前面使用的 `np.bool_` 数组不同，因为现在，我们使用的是字节中的各个位来表示集合中的实体。注意，对于一个给定的 bitset，我们可能需要多个字节，具体取决于我们所需的最大元素数。我们可以对 `qs` 中的每个问题的字节使用快速的 bitwise_and 来查找集合交集，从而找到回答了 `qs` 中所有问题的用户数。

下面是我们将用到的 `bitset` 函数：

```py
def bitset_create(size):
    """Initialise an empty bitset"""
    size_in_int64 = int(np.ceil(size / 64))
    return np.zeros(size_in_int64, dtype=np.int64)

```


```py
def bitset_add(arr, pos):
    """Add an element to a bitset"""
    int64_idx = pos // 64
    pos_in_int64 = pos % 64
    arr[int64_idx] |= np.int64(1) << np.int64(pos_in_int64)
```


```py
def bitset_to_list(arr):
    """Convert a bitset back into a list of ints"""
    result = []
    for idx in range(arr.shape[0]):
        if arr[idx] == 0:
            continue
        for pos in range(64):
            if (arr[idx] & (np.int64(1) << np.int64(pos))) != 0:
                result.append(idx * 64 + pos)
    return np.array(result)

```

然后，我们可以用下述方法初始化 bitset：

```py
users_who_answered_q = np.array(
    [bitset_create(data.user.nunique()) for _ in range(data.question.nunique())]
)
for q, u in data[["question", "user"]].values:
    bitset_add(users_who_answered_q[q], u)
```

让我们看看所得速度提升：

```sh
Avg time per iteration:  550 μs
Speedup over baseline:   64.2x

% Time  Line Contents
=====================
        def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):
   0.0      num_qs = qs_combinations.shape[0]
   0.0      bitset_size = users_who_answered_q[0].shape[0]
   0.0      result = np.empty(qs_combinations.shape[0], dtype=np.float64)
   0.0      for i in range(num_qs):
   0.0          qs = qs_combinations[i]
   0.3          user_sets_for_qs = users_who_answered_q[qs_combinations[i]]
   0.4          answered_all = np.bitwise_and.reduce(user_sets_for_qs)
  96.7          answered_all = bitset_to_list(answered_all)
   0.6          qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)
   0.0          user_grand_total = grand_totals[answered_all]
   1.9          result[i] = corrcoef(qs_total, user_grand_total)
   0.0      return result
```

看起来有些倒退了，使用 `bitset_to_list` 操作花费了很多时间。

### 优化 10 - Numba 和 *bitset_to_list*


让我们将 `bitset_to_list` 转换为编译后的代码。为此，我们可以添加一个  Numba 装饰器：

```py
@numba.njit
def bitset_to_list(arr):
    result = []
    for idx in range(arr.shape[0]):
        if arr[idx] == 0:
            continue
        for pos in range(64):
            if (arr[idx] & (np.int64(1) << np.int64(pos))) != 0:
                result.append(idx * 64 + pos)
    return np.array(result)
```

让我们评估下：

```sh
Benchmark #14: bitsets, with numba on bitset_to_list
Using 1000 iterations...

Avg time per iteration:  19 μs
Speedup over baseline:   1801.2x

% Time  Line Contents
=====================
        def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):
   0.0      num_qs = qs_combinations.shape[0]
   0.0      bitset_size = users_who_answered_q[0].shape[0]
   0.0      result = np.empty(qs_combinations.shape[0], dtype=np.float64)
   0.3      for i in range(num_qs):
   0.6          qs = qs_combinations[i]
   8.1          user_sets_for_qs = users_who_answered_q[qs_combinations[i]]
  11.8          answered_all = np.bitwise_and.reduce(user_sets_for_qs)
   7.7          answered_all = bitset_to_list(answered_all)
  16.2          qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)
   1.1          user_grand_total = grand_totals[answered_all]
  54.1          result[i] = corrcoef(qs_total, user_grand_total)
   0.0      return result
```

和原始代码相比，我们获得了 1,800 倍多代码执行速度提升。回想一下优化 7，在引入 Numba 之前，代码速度提升是 814 倍。（优化 8 是 4142 倍，但那是在内循环上使用了 `parallel=True`，所以它与上面的不具有可比性。）


### 优化 11 - Numba 和 *corrcoef*


The corrcoef line is again standing out as slow above. Let’s use `corrcoef` decorated with Numba.



```py
@numba.njit
def corrcoef_numba(a, b):
    """same as np.corrcoef(a, b)[0, 1]"""
    n = len(a)
    sum_a = sum(a)
    sum_b = sum(b)
    sum_ab = sum(a * b)
    sum_a_sq = sum(a * a)
    sum_b_sq = sum(b * b)
    num = n * sum_ab - sum_a * sum_b
    den = math.sqrt(n * sum_a_sq - sum_a**2) * math.sqrt(n * sum_b_sq - sum_b**2)
    return np.nan if den == 0 else num / den
```

以及基准：


```sh
Avg time per iteration:  11 μs
Speedup over baseline:   3218.9x

% Time  Line Contents
=====================
        def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):
   0.0      num_qs = qs_combinations.shape[0]
   0.0      bitset_size = users_who_answered_q[0].shape[0]
   0.0      result = np.empty(qs_combinations.shape[0], dtype=np.float64)
   0.7      for i in range(num_qs):
   1.5          qs = qs_combinations[i]
  15.9          user_sets_for_qs = users_who_answered_q[qs_combinations[i]]
  26.1          answered_all = np.bitwise_and.reduce(user_sets_for_qs)
  16.1          answered_all = bitset_to_list(answered_all)
  33.3          qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)
   2.0          user_grand_total = grand_totals[answered_all]
   4.5          result[i] = corrcoef_numba(qs_total, user_grand_total)
   0.0      return result
```

棒，另一个大的速度提升。

### 优化 12 - Numba 和 *bitset_and*


我们引入 `bitwise_and` 来替换 `np.bitwise_and.reduce`，然后对其进行 jit 编译。

```py
@numba.njit
def bitset_and(arrays):
    result = arrays[0].copy()
    for i in range(1, len(arrays)):
        result &= arrays[i]
    return result
```


```sh
Benchmark #16: numba also on bitset_and
Using 1000 iterations...

Avg time per iteration:  8.9 μs
Speedup over baseline:   3956.7x

% Time  Line Contents
=====================
        def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):
   0.1      num_qs = qs_combinations.shape[0]
   0.0      bitset_size = users_who_answered_q[0].shape[0]
   0.1      result = np.empty(qs_combinations.shape[0], dtype=np.float64)
   1.0      for i in range(num_qs):
   1.5          qs = qs_combinations[i]
  18.4          user_sets_for_qs = users_who_answered_q[qs_combinations[i]]
  16.1          answered_all = bitset_and(user_sets_for_qs)
  17.9          answered_all = bitset_to_list(answered_all)
  37.8          qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)
   2.4          user_grand_total = grand_totals[answered_all]
   4.8          result[i] = corrcoef_numba(qs_total, user_grand_total)
   0.0      return result
```

### 优化 12 - 整个函数上的 Numba

现在，上面的代码比原始代码快得多，计算量相当均匀地分布在循环中的几行代码上。事实上，看起来最慢的那一行正在执行的是 NumPy 索引操作，这已经相当快了。那么，让我们用 Numba 编译整个函数。

```py
@numba.njit(parallel=False)
def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):
    result = np.empty(len(qs_combinations), dtype=np.float64)
    for i in numba.prange(len(qs_combinations)):
        qs = qs_combinations[i]
        user_sets_for_qs = users_who_answered_q[qs, :]
        answered_all = user_sets_for_qs[0]
        # numba doesn't support np.logical_and.reduce
        for j in range(1, len(user_sets_for_qs)):
            answered_all *= user_sets_for_qs[j]
        answered_all = np.where(answered_all)[0]
        qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)
        user_grand_total = grand_totals[answered_all]
        result[i] = corrcoef_numba(qs_total, user_grand_total)
    return result
```


```sh
Avg time per iteration:  4.2 μs
Speedup over baseline:   8353.2x

```

现在，使用 `parallel=True`：



```sh
Avg time per iteration:  960 ns
Speedup over baseline:   36721.4x

```

可以了，很好，我们比原始代码快了 36,000 倍。

### 优化 13 - Numba，inline with accumulation instead of arrays

我们接下来要干什么呢？...好吧，在上面的代码中仍然有相当多的将值放入数组中，然后传递它们的操作。由于我们正在努力优化此代码，因此我们可以查看 corrcoef 的计算方式，染灰会发现我们不需要构建数组 `answered_all` 和 `user_grand_total`，相反，我们可以在循环时累积值。

这里是代码（我们还启用了一些编译器优化，例如禁用数组的 `boundschecking` 和启用 `fastmath`）。


```py
@numba.njit(boundscheck=False, fastmath=True, parallel=False, nogil=True)
def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):
    num_qs = qs_combinations.shape[0]
    bitset_size = users_who_answered_q[0].shape[0]
    corrs = np.empty(qs_combinations.shape[0], dtype=np.float64)
    for i in numba.prange(num_qs):
        # bitset will contain users who answered all questions in qs_array[i]
        bitset = users_who_answered_q[qs_combinations[i, 0]].copy()
        for q in qs_combinations[i, 1:]:
            bitset &= users_who_answered_q[q]
        # retrieve stats for the users to compute correlation
        n = 0.0
        sum_a = 0.0
        sum_b = 0.0
        sum_ab = 0.0
        sum_a_sq = 0.0
        sum_b_sq = 0.0
        for idx in range(bitset_size):
            if bitset[idx] != 0:
                for pos in range(64):
                    if (bitset[idx] & (np.int64(1) << np.int64(pos))) != 0:
                        user_idx = idx * 64 + pos
                        score_for_qs = 0.0
                        for q in qs_combinations[i]:
                            score_for_qs += score_matrix[user_idx, q]
                        score_for_user = grand_totals[user_idx]
                        n += 1.0
                        sum_a += score_for_qs
                        sum_b += score_for_user
                        sum_ab += score_for_qs * score_for_user
                        sum_a_sq += score_for_qs * score_for_qs
                        sum_b_sq += score_for_user * score_for_user
        num = n * sum_ab - sum_a * sum_b
        den = np.sqrt(n * sum_a_sq - sum_a**2) * np.sqrt(n * sum_b_sq - sum_b**2)
        corrs[i] = np.nan if den == 0 else num / den
    return corrs
```

我们从使用 `parallel=False` 开始。

```sh
Avg time per iteration:  1.7 μs
Speedup over baseline:   20850.5x

```

这应该与优化 12 中设置 `parallel=False` 的情况（测量结果为 8353 倍提升）进行比较。

现在，使用 `parallel=True`。

```sh
Avg time per iteration:  210 ns
Speedup over baseline:   170476.3x

```

很好，我们已经将 Python 基线的速度提高了 170,000 倍。


### 总结

得益于 Numba 和 NumPy，我们已经能够获得使优化的 Rust 代码变得更快的大部分功能，特别是位集、SIMD 和循环级并行性。首先，我们通过 JIT 编译了一些辅助函数，使原始 Python 代码变得相当快，但最后，我们对整个代码进行了 JIT 编译，并为此优化了代码。我们采取了试验和改进的方法，使用分析将我们的工作重点放在最慢的代码行上。我们展示了可以使用 Numba 将 JIT 编译的代码逐渐混合到我们的 Python 代码中。我们可以立即将此代码放入现有的 Python 代码库中。然而，我们没有达到像优化后的 Rust 代码那样 180,000 倍的速度提升，我们推出了自己的相关性和位集实现，而 Rust 代码能够使用一些库来实现这些功能，同时保持其性能。

这是一个有趣的练习，希望它展示了 Python 生态系统中的一些有用的工具。

我会特别推荐其中某种方法吗？不，要使用哪种方法取决于具体情况。


#### 笔记

完整的代码在[这里（GitHub）](https://github.com/sradc/corrset-benchmark-fork/tree/main/python_optimization)。